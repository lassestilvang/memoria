# GEMINI.md - Memoria Project Context

## Project Overview
**Memoria** is a premium voice-first AI application designed to help elderly users preserve their life stories. It features an empathetic AI interviewer that asks questions, listens to stories, and provides human-like follow-up questions. It transforms shared memories into a professionally illustrated digital memoir PDF.

### Key Pillars
- **Infinite Memory Engine (RAG)**: Automatically extracts and retrieves past memories to maintain continuity across sessions.
- **Professional Artifact Generation**: Creates high-quality PDF memoirs with cinematic AI-generated illustrations.
- **Immersive Multimodal Interaction**: Supports vision analysis of uploaded photos to spark conversation.
- **Family Collaboration**: A dedicated dashboard for family members to suggest "Memory Seeds" (topics) for the interview.

### Architecture
- **Frontend**: A React 19 application providing a premium dark-mode voice interface using the ElevenLabs React SDK and Tailwind CSS 4.
- **Backend (The Brain)**: A Python FastAPI application acting as a custom LLM for ElevenLabs. It integrates with Google Vertex AI for conversation, embeddings, and image generation.
- **Voice Agent**: Powered by ElevenLabs Conversational AI, handling STT and TTS with a custom WebSocket bridge for real-time memory extraction.

### Tech Stack
- **Frontend**: React 19, Vite, Tailwind CSS 4, TypeScript, `@elevenlabs/react`.
- **Backend**: Python 3.9+, FastAPI, `google-cloud-aiplatform` (Vertex AI), `pydantic`, `sqlite3`, `reportlab`.
- **LLM**: Google Gemini 1.5 Flash (via Vertex AI).
- **Embeddings**: `text-embedding-004`.
- **Image Generation**: `imagen-3.0-generate-001`.
- **Deployment**: Google Cloud Run, Google Cloud Build (CI/CD).

---

## Building and Running

### Backend
1. **Navigate to backend**: `cd backend`
2. **Setup virtual environment**:
   ```bash
   python3 -m venv venv
   source venv/bin/activate
   pip install -r requirements.txt
   ```
3. **Configure environment**: Create a `.env` file with:
   ```env
   GOOGLE_CLOUD_PROJECT=your-project-id
   GOOGLE_CLOUD_LOCATION=us-central1
   ```
4. **Run locally**:
   ```bash
   python main.py
   ```
   *The backend runs on `http://localhost:8000`.*

### Frontend
1. **Navigate to frontend**: `cd frontend`
2. **Install dependencies**: `npm install`
3. **Configure environment**: Create a `.env` file with:
   ```env
   VITE_ELEVENLABS_AGENT_ID=your-agent-id
   ```
4. **Run development server**: `npm run dev`
   *The frontend runs on `http://localhost:5173`.*

---

## Development Conventions

### Backend
- **Memory Pipeline**: Conversation fragments are automatically extracted in background tasks and stored in SQLite.
- **RAG Implementation**: Relevant past memories are injected into the Gemini system prompt based on cosine similarity search.
- **Vision Integration**: The `/vision-context` endpoint analyzes photos and adds descriptions to the memory store.
- **Memoir Export**: The `/export` endpoint generates a PDF using `reportlab`, with illustrations dynamically generated by Imagen.

### Frontend
- **Dark Mode**: Uses a sophisticated, high-contrast dark theme for elderly accessibility.
- **Family Dashboard**: Allows external users to view memories and add "Seeds" for the interviewer to cover.
- **ElevenLabs Integration**: Uses the `useConversation` hook with custom latency optimizations.

---

## Key Files
- `backend/main.py`: Core FastAPI app and OpenAI-compatible endpoint.
- `backend/rag_service.py`: Vector search and embedding logic.
- `backend/database.py`: SQLite persistence for fragments and seeds.
- `backend/memoir_generator.py`: PDF generation logic with ReportLab.
- `backend/imagen_service.py`: Vertex AI Imagen integration for memoir illustrations.
- `frontend/src/components/Interviewer.tsx`: Main voice interface component.
- `frontend/src/components/FamilyDashboard.tsx`: Dashboard for family collaboration.
- `cloudbuild.yaml`: Google Cloud Build pipeline configuration.

---

## Deployment & Infrastructure
- **CI/CD**: Managed by `cloudbuild.yaml`. Pushes to GitHub trigger builds that deploy to Google Cloud Run.
- **Cloud Run**: The service is named `memoria-brain` and must be public (`--allow-unauthenticated`) for ElevenLabs to access it.
